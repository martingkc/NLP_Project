{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ReadMe\n",
        "On this notebook we finetune Qwen 2.5 VL (3B and 7B) using Lora adapters with Unsloth. At the end of the notebook we test our models performance using our eval function"
      ],
      "metadata": {
        "id": "Dmoi-mrIXvOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "64qV_CFwWiLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pip3-autoremove\n",
        "!pip-autoremove torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install unsloth==2025.5.6\n",
        "!pip install VLLM==0.8.4\n",
        "!pip install transformers==4.51.3"
      ],
      "metadata": {
        "id": "Wb4ughrAWiLr",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:01:42.427894Z",
          "iopub.execute_input": "2025-05-23T15:01:42.428131Z",
          "iopub.status.idle": "2025-05-23T15:07:03.658866Z",
          "shell.execute_reply.started": "2025-05-23T15:01:42.428113Z",
          "shell.execute_reply": "2025-05-23T15:07:03.658081Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsloth\n",
        "For the finetuning process we're going to use the UNSLOTH library. Unsloth offers faster and more memory efficient finetuning compared to the huggingface libraries. Using HF we wouldve required a more powerful gpu."
      ],
      "metadata": {
        "id": "m0i-eAVsWiLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastVisionModel\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:07:03.660412Z",
          "iopub.execute_input": "2025-05-23T15:07:03.660627Z",
          "iopub.status.idle": "2025-05-23T15:07:40.123655Z",
          "shell.execute_reply.started": "2025-05-23T15:07:03.660607Z",
          "shell.execute_reply": "2025-05-23T15:07:40.123104Z"
        },
        "id": "SD3iD-g2mPds",
        "outputId": "e92a6062-fc9e-4b28-e57b-dd435fd3f907"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2025-05-23 15:07:15.937804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748012836.148091      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748012836.214150      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "🦥 Unsloth Zoo will now patch everything to make training faster!\nINFO 05-23 15:07:35 [__init__.py:239] Automatically detected platform cuda.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nnfaEASFmPds"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Qwen2.5-VL-3B-Instruct-unsloth-bnb-4bit\",\n",
        "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ],
      "metadata": {
        "id": "QmUBVEnvCDJv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Picking the layers to train"
      ],
      "metadata": {
        "id": "VQhAWMwcmPdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = True,\n",
        "    finetune_language_layers   = True,\n",
        "    finetune_attention_modules = True,\n",
        "    finetune_mlp_modules       = True,\n",
        "\n",
        "    r = 32,\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0.1,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data Preparation\n",
        "Since the dataset is really big and our compute power so limited we're going to used a Dataset sampled from the original [NIH-CXR14-BiomedCLIP-Features](https://huggingface.co/datasets/Yasintuncer/NIH-CXR14-BiomedCLIP-Features/viewer/default/train?row=0&views%5B%5D=train) dataset.\n",
        "\n",
        "There are 200 samples for label which in total are 15. This number has been chosen because our label with the lowest number of samples was `Hernea` with aprox 250 samples whereas the label with the second lowest amount of samples was `Emphysema` with aprox 1000 samples. In order to reduce the bias caused by the samples we decided to pick 200 samples for each in Training and 50 for Testing."
      ],
      "metadata": {
        "id": "vITh0KVJ10qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"Martingkc/MediBert_Dataset\")\n",
        "dataset_testvalid = dataset[\"test\"].train_test_split(test_size=0.2)\n",
        "dataset_train = dataset[\"train\"]\n",
        "dataset_test = dataset_testvalid[\"test\"]\n",
        "dataset_valid = dataset_testvalid[\"train\"]"
      ],
      "metadata": {
        "id": "LjY75GoYUCB8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:07:40.12639Z",
          "iopub.execute_input": "2025-05-23T15:07:40.127167Z",
          "iopub.status.idle": "2025-05-23T15:07:53.820082Z",
          "shell.execute_reply.started": "2025-05-23T15:07:40.127143Z",
          "shell.execute_reply": "2025-05-23T15:07:53.819298Z"
        },
        "outputId": "f06d3480-fe9e-4908-db63-a78cc5353ab2",
        "colab": {
          "referenced_widgets": [
            "a37d791666294dc683c0873dff516264",
            "9754817e42e74ada84cd054906333e68",
            "799ee33599b7462ea3e4909350e7a2d4",
            "f914f2653d2845a4a9306a34007c370e",
            "ed0ea590921a48d9a591580636c77840"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/1.16k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a37d791666294dc683c0873dff516264"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00002.parquet:   0%|          | 0.00/480M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9754817e42e74ada84cd054906333e68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00001-of-00002.parquet:   0%|          | 0.00/485M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "799ee33599b7462ea3e4909350e7a2d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/2380 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f914f2653d2845a4a9306a34007c370e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/2380 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed0ea590921a48d9a591580636c77840"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples from the DS\n",
        "#### Image"
      ],
      "metadata": {
        "id": "W1W2Qhsz6rUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[2][\"Image\"]"
      ],
      "metadata": {
        "id": "uOLWY2936t1n",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text"
      ],
      "metadata": {
        "id": "EIAaSJWvmPdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[2][\"Texts\"]"
      ],
      "metadata": {
        "id": "VTzhtzNRAEL1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formatting DS and defining a prompt\n",
        "- UNSLOTH accepts data structured as follows\n",
        "\n",
        "```python\n",
        "[\n",
        "{ \"role\": \"user\",\n",
        "  \"content\": [{\"type\": \"text\",  \"text\": Q}, {\"type\": \"image\", \"image\": image} ]\n",
        "},\n",
        "{ \"role\": \"assistant\",\n",
        "  \"content\": [{\"type\": \"text\",  \"text\": A} ]\n",
        "},\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "K9CBpiISFa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"You are an expert radiologist AI assistant. Your task is to carefully and thoroughly analyze a given chest X-ray image and provide a a concise, two-sentence summary. Your response MUST strictly adhere to the following format:\n",
        "\n",
        "**Sentence 1 (Findings):**\n",
        "This sentence MUST begin with \"This photo of a chest x-ray shows \".\n",
        "*   If there are **multiple abnormalities**, it must continue with: \"multiple findings including [FINDING_1, FINDING_2, ...].\" (e.g., \"multiple findings including Atelectasis, Cardiomegaly, and Effusion.\")\n",
        "*   If there is **exactly one abnormality**, it must continue with: \"a [FINDING] finding.\" (e.g., \"a Hernia finding.\")\n",
        "*   If there are **no abnormalities**, it must continue with: \"no findings.\" (e.g., \"no findings.\")\n",
        "\n",
        "The ONLY permissible terms for [FINDING] are: Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule, Pneumonia, Pneumothorax, Consolidation, Edema, Emphysema, Fibrosis, Hernia, Pleural Thickening.\n",
        "\n",
        "**Sentence 2 (Projection):**\n",
        "This sentence MUST be exactly: \"The image is taken from a [PROJECTION] view.\"\n",
        "*   [PROJECTION] MUST be one of: \"PA\" or \"AP\".\n",
        "\n",
        "**CRITICAL: Do not deviate from this two-sentence structure and wording. Use only the provided terms for findings.**\n",
        "”\"\"\"\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    conversation = [\n",
        "        { \"role\": \"user\",\n",
        "          \"content\" : [\n",
        "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
        "            {\"type\" : \"image\", \"image\" : sample[\"Image\"]} ]\n",
        "        },\n",
        "        { \"role\" : \"assistant\",\n",
        "          \"content\" : [\n",
        "            {\"type\" : \"text\",  \"text\"  : sample[\"Texts\"]} ]\n",
        "        },\n",
        "    ]\n",
        "    return { \"messages\" : conversation }\n",
        "pass"
      ],
      "metadata": {
        "id": "oPXzJZzHEgXe",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:07:53.822345Z",
          "iopub.execute_input": "2025-05-23T15:07:53.82283Z",
          "iopub.status.idle": "2025-05-23T15:07:53.828954Z",
          "shell.execute_reply.started": "2025-05-23T15:07:53.822802Z",
          "shell.execute_reply": "2025-05-23T15:07:53.828213Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert DS in the Unsloth Format"
      ],
      "metadata": {
        "id": "FY-9u-OD6_gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset = [convert_to_conversation(sample) for sample in dataset_train]\n",
        "converted_dataset_valid = [convert_to_conversation(sample) for sample in dataset_testvalid[\"test\"]]\n",
        "converted_dataset_test = [convert_to_conversation(sample) for sample in dataset_testvalid[\"train\"]]"
      ],
      "metadata": {
        "id": "gFW2qXIr7Ezy",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset[0]"
      ],
      "metadata": {
        "id": "gGFzmplrEy9I",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Finetune Test"
      ],
      "metadata": {
        "id": "Vs7OSF9GmPdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)\n",
        "\n",
        "image = dataset['train'][0][\"Image\"]\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]\n",
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ],
      "metadata": {
        "id": "vcat4UxA81vr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Train the model\n",
        "Now let's use Huggingface's `SFTTrainer`, with 3 epochs and a low learning rate of 5e-5 and a validation set that is going to be used every 100 steps. For the lora adapters we chose an r value of 24 and an alpha value of 32 increasing the layers trained."
      ],
      "metadata": {
        "id": "idAEIeSQ3xdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bf16_supported\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "\n",
        "\n",
        "FastVisionModel.for_training(model)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
        "    train_dataset = converted_dataset,\n",
        "    eval_dataset = converted_dataset_valid,\n",
        "\n",
        "    args = SFTConfig(\n",
        "        num_train_epochs = 2,               # fixed total steps\n",
        "        warmup_steps = 20,          # ~10% warm-up\n",
        "        lr_scheduler_type = \"cosine\",         # smooth decay\n",
        "        learning_rate = 5e-5,                 # gentle LR\n",
        "        per_device_train_batch_size = 2,      # or bump to 4 if you can\n",
        "        gradient_accumulation_steps = 4,      # adjust if batch size increases\n",
        "        fp16 = not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.02,\n",
        "        logging_steps = 50,\n",
        "        eval_strategy = \"steps\",\n",
        "        eval_steps = 100,\n",
        "        save_strategy = \"steps\",\n",
        "        save_steps = 100,\n",
        "        load_best_model_at_end = True,\n",
        "        metric_for_best_model = \"loss\",\n",
        "        report_to = \"none\",\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"caption\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc = 4,\n",
        "        max_seq_length = 2048,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "95_Nn-89DhsL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2ejIt2xSNKKp",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n"
      ],
      "metadata": {
        "id": "uMuVrWbjAzhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "HF_TOKEN = user_secrets.get_secret(\"Hugging_Face_Token\")\n",
        "\n",
        "model.push_to_hub(\"Martingkc/Qwen_2.5VL_3B_3_NIHCXR14_LORA\", token =HF_TOKEN)\n",
        "tokenizer.push_to_hub(\"Martingkc/Qwen_2.5VL_3B_3_NIHCXR14_LORA\", token =HF_TOKEN)"
      ],
      "metadata": {
        "id": "upcOlWe7A1vc",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test & Inference"
      ],
      "metadata": {
        "id": "t_fe5RpKmPdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[2][\"Texts\"]"
      ],
      "metadata": {
        "id": "oKlh5ObFgq1C",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)\n",
        "\n",
        "image = dataset_test[2][\"Image\"]\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]\n",
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ],
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using LoRa Adapters on HF\n",
        "Load our LoRa Adapters. Unsloth will load the adapters from the HF repo and merge it automatically with our base model."
      ],
      "metadata": {
        "id": "4yw8twnfmPdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from unsloth import FastVisionModel\n",
        "\n",
        "MODEL_7B = \"Martingkc/Qwen_2.5VL_NIHCXR14_LORA\"\n",
        "MODEL_3B = \"Martingkc/Qwen_2.5VL_3B_3_NIHCXR14_LORA\"\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "model_name=MODEL_3B,\n",
        "max_seq_length=1024,\n",
        "load_in_4bit=True,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:07:53.82961Z",
          "iopub.execute_input": "2025-05-23T15:07:53.829914Z",
          "iopub.status.idle": "2025-05-23T15:08:38.332665Z",
          "shell.execute_reply.started": "2025-05-23T15:07:53.829888Z",
          "shell.execute_reply": "2025-05-23T15:08:38.332081Z"
        },
        "id": "W6DY3J97mPdw",
        "outputId": "94fe0407-43fa-4537-c96d-c173f29e5eda",
        "colab": {
          "referenced_widgets": [
            "6668b2f80a8c48fd83ef3b110b9f4e32",
            "a38cba84cf494c1c9fd911228e0c9485",
            "1d1505feebcc4267aeb471de4625c843",
            "6caf64dcbdfb4fbd9739dca144fff2a3",
            "54d6b8cb55674f4dbabd64f82b4cbcd3",
            "41c764ef6c944731ace1474f131ef339",
            "0af6f30fc5f4412a896b5c0e6ffe3e61",
            "80cd4c930fd24b569d01c853704efa1e",
            "02a66c97041742b695e668ca3f8d2e35",
            "af453dffa3d44979b7580f1bfba38a7b",
            "88444dc2327c4e16822cc5a0412dc43a",
            "04b2444a0fcc44ac99dd8cabdc5824b3"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "==((====))==  Unsloth 2025.5.6: Fast Qwen2 patching. Transformers: 4.51.3. vLLM: 0.8.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/3.79G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6668b2f80a8c48fd83ef3b110b9f4e32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a38cba84cf494c1c9fd911228e0c9485"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d1505feebcc4267aeb471de4625c843"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/5.80k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6caf64dcbdfb4fbd9739dca144fff2a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54d6b8cb55674f4dbabd64f82b4cbcd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41c764ef6c944731ace1474f131ef339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0af6f30fc5f4412a896b5c0e6ffe3e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80cd4c930fd24b569d01c853704efa1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02a66c97041742b695e668ca3f8d2e35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "chat_template.jinja:   0%|          | 0.00/1.02k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af453dffa3d44979b7580f1bfba38a7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88444dc2327c4e16822cc5a0412dc43a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/329M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04b2444a0fcc44ac99dd8cabdc5824b3"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "def generate_caption(image):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]}\n",
        "    ]\n",
        "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "    inputs = tokenizer(\n",
        "        image,\n",
        "        input_text,\n",
        "        add_special_tokens = False,\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "    tokens = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                       use_cache = True, temperature = 1.5, min_p = 0.1)\n",
        "    decoded_tokens = [tokenizer.decode(id) for id in tokens]\n",
        "\n",
        "    return \"\".join(decoded_tokens).split(\"<|im_start|>assistant\\n\")[-1].replace(\"<|im_end|>\", \"\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:08:38.333458Z",
          "iopub.execute_input": "2025-05-23T15:08:38.333685Z",
          "iopub.status.idle": "2025-05-23T15:08:38.342626Z",
          "shell.execute_reply.started": "2025-05-23T15:08:38.333667Z",
          "shell.execute_reply": "2025-05-23T15:08:38.341895Z"
        },
        "id": "V_I4u8NGmPdw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing\n",
        "We defined the following evaluation function that takes a list containing the base and predicted texts extracts the labels and gives the f1, recall, precision and accuracy scores. And it also calculates the rouge scores of the base and predicted texts. Unsloth doesnt give access to the Logits so were unable to calculate probability based scores such as AUC ROC."
      ],
      "metadata": {
        "id": "CAudNVqpmPdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score evaluate"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:08:38.343321Z",
          "iopub.execute_input": "2025-05-23T15:08:38.343581Z",
          "iopub.status.idle": "2025-05-23T15:08:43.816308Z",
          "shell.execute_reply.started": "2025-05-23T15:08:38.343564Z",
          "shell.execute_reply": "2025-05-23T15:08:43.81556Z"
        },
        "id": "XToWU0WjmPdw",
        "outputId": "a718c1d1-1b56-459d-ffe3-bcc158ed52d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=14b42eb8407e2b8a370d602e7ba453e5f960bf77fd366e30bb54b19b7404eeb2\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.3 rouge_score-0.1.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "label_cols = [\n",
        "\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
        "\"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\",\n",
        "\"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\",\n",
        "\"Hernia\", \"Pleural Thickening\", \"no findings\",\"AP\", \"PA\"\n",
        "]\n",
        "\n",
        "def eval_model(pred_texts, base_texts):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        - `pred`: array of len 100 containing predictions\n",
        "        - `base`: array of len 100 containing reference sentences\n",
        "    \"\"\"\n",
        "    pred_labels = []\n",
        "    base_labels = []\n",
        "    for p, b in zip(pred_texts, base_texts):\n",
        "        p = p.lower()\n",
        "        b = b.lower()\n",
        "\n",
        "        p_vec = []\n",
        "        b_vec = []\n",
        "        for lbl in label_cols:\n",
        "            lbl_lc = lbl.lower()\n",
        "            p_vec.append(1 if lbl_lc in p else 0)\n",
        "            b_vec.append(1 if lbl_lc in b else 0)\n",
        "\n",
        "        pred_labels.append(p_vec)\n",
        "        base_labels.append(b_vec)\n",
        "\n",
        "    rouge_scores = rouge.compute(predictions=pred_texts, references=base_texts)\n",
        "    f1 = f1_score(pred_labels, base_labels,average='macro',zero_division=0)\n",
        "    recall = recall_score(pred_labels, base_labels,average='micro',zero_division = 0 )\n",
        "    precision = precision_score(pred_labels, base_labels,average='micro',zero_division = 0 )\n",
        "    accuracy = accuracy_score(pred_labels, base_labels)\n",
        "\n",
        "    return {\n",
        "        \"f1@100\": f1,\n",
        "        \"recall@100\": recall,\n",
        "        \"accuracy@100\": accuracy,\n",
        "        \"precision@100\": precision,\n",
        "        \"rouge_scores@100\": rouge_scores\n",
        "    }\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:08:43.817272Z",
          "iopub.execute_input": "2025-05-23T15:08:43.817575Z",
          "iopub.status.idle": "2025-05-23T15:08:44.984101Z",
          "shell.execute_reply.started": "2025-05-23T15:08:43.817548Z",
          "shell.execute_reply": "2025-05-23T15:08:44.983567Z"
        },
        "id": "qwl6_8VUmPdw",
        "outputId": "0468b2ec-cb8f-49f9-f34c-9395be2881c6",
        "colab": {
          "referenced_widgets": [
            "0d470df856c34a8db6714a5a7255a807"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d470df856c34a8db6714a5a7255a807"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "test_samples_100 = dataset_test.select(random.sample(range(1, len(dataset_test)), 100))\n",
        "\n",
        "\n",
        "base_text = []\n",
        "pred_text = []\n",
        "\n",
        "for idx, row in enumerate(test_samples_100):\n",
        "    base_text.append(row[\"Texts\"])\n",
        "    pred_text.append(generate_caption(row[\"Image\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:08:44.984883Z",
          "iopub.execute_input": "2025-05-23T15:08:44.985154Z",
          "iopub.status.idle": "2025-05-23T15:22:07.340094Z",
          "shell.execute_reply.started": "2025-05-23T15:08:44.98513Z",
          "shell.execute_reply": "2025-05-23T15:22:07.339542Z"
        },
        "id": "PNZ8Z2mKmPdw",
        "outputId": "873f0b37-c726-44a1-b183-c039dc82b24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "This photo of a chest x-ray shows multiple findings including Atelectasis, Infiltration, and Mass. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Emphysema, Infiltration, Mass, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Infiltration, Mass, Nodule, Pleural_Thickening, and Pneumothorax. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Emphysema, Mass, Nodule. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Infiltration, Pneumothorax, and Consolidation. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Infiltration, and Pleural_Thickening. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Edema, Infiltration, Nodule, and Pneumothorax. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly, Edema, and Effusion. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Cardiomegaly finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Hernia finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Edema, Effusion, Infiltration, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Infiltration, Pleural_Thickening, and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Emphysema and Pleural_Thickening. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Pneumonia. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Pneumothorax. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Effusion, Infiltration, and Pleural_Thickening. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Effusion, and Nodule. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Fibrosis finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Atelectasis finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Effusion, Infiltration, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Emphysema, Hernia, Pneumothorax, and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Effusion finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Emphysema, and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Hernia finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Infiltration, and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows a Edema finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly and Effusion. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly and Infiltration. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Fibrosis, and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Infiltration, and Pneumothorax. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Consolidation and Edema. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Edema, Effusion, and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Effusion finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Infiltration finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Emphysema, Pneumonia, and Pneumothorax. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Fibrosis, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Infiltration finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows a Nodule finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Edema, Effusion, and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Effusion, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Atelectasis finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Mass, and Nodule. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Effusion. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Consolidation, Effusion, and Fibrosis. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Fibrosis. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly, Consolidation, and Effusion. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly, Consolidation, and Pleural_Thickening. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Edema finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion, Hernia, and Nodule. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Edema finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Cardiomegaly. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Cardiomegaly finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Emphysema. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Effusion, Infiltration, Pneumothorax, and Pneumonia. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion and Mass. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Pneumothorax finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Effusion and Mass. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Infiltration, Mass, and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Cardiomegaly, Infiltration, and Nodule. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows a Emphysema finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Edema, Effusion, Infiltration, Pneumonia, Pleural Thickening. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Cardiomegaly, Effusion, and Infiltration. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Edema, Effusion, and Pneumonia. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Emphysema, Infiltration, and Pneumothorax. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis and Pleural_Thickening. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Atelectasis, Emphysema, and Pneumothorax. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows no findings available. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows a Cardiomegaly finding. The image is taken from a AP view.<|im_end|>\nThis photo of a chest x-ray shows a Nodule finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows a Pleural_Thickening finding. The image is taken from a PA view.<|im_end|>\nThis photo of a chest x-ray shows multiple findings including Infiltration and Effusion. The image is taken from a AP view.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(pred_text, base_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-23T15:22:07.340956Z",
          "iopub.execute_input": "2025-05-23T15:22:07.341625Z",
          "iopub.status.idle": "2025-05-23T15:22:07.591909Z",
          "shell.execute_reply.started": "2025-05-23T15:22:07.341605Z",
          "shell.execute_reply": "2025-05-23T15:22:07.591356Z"
        },
        "id": "RW7w8KaXmPdw",
        "outputId": "1418d27a-72fd-47d0-e081-8bfa4c02bd0c"
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'f1@100': 0.19134492879408804,\n 'recall@100': 0.3523489932885906,\n 'accuracy@100': 0.05,\n 'precision@100': 0.38181818181818183,\n 'rouge_scores@100': {'rouge1': 0.8294648597229838,\n  'rouge2': 0.7386126460556653,\n  'rougeL': 0.8279210471233425,\n  'rougeLsum': 0.8278508397958884}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result for 7B Parameter Qwen VL 2.5\n",
        "{'f1@100': 0.1685669275460801,\n",
        " 'recall@100': 0.3839541547277937,\n",
        " 'accuracy@100': 0.01,\n",
        " 'precision@100': 0.47017543859649125,\n",
        " 'rouge_scores@100': {'rouge1': 0.8524994674908319,\n",
        "  'rouge2': 0.7473405414870823,\n",
        "  'rougeL': 0.8443709933441017,\n",
        "  'rougeLsum': 0.8439830183982576}}"
      ],
      "metadata": {
        "id": "hOf-Ae2vmPd1"
      }
    }
  ]
}